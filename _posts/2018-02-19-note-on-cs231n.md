---
  layout: post
  title: cs231n笔记之优化
  categories: MachineLearning
  tags:
---

本文是对cs231中优化部分的简略笔记

Learning
===

前面讲了神经网络的静态部分:如何建立起神经网络的连接、数据和损失函数，本节讲解参数的学习过程

Gradient Checks

梯度检查其实就是比较梯度的解析解(analytic gradient)和数值解(numerical gradient)。这个过程比较复杂且容易出错。本文介绍了一些tips/tricks和需要注意的问题

**Use the centered formula**

计算梯度的数值解时你看到的是下面的优先差分近似公式( finite difference approximation ）

$$
\frac{df(x)}{dx} = \frac{f(x + h) - f(x)}{h} \hspace{0.1in} \text{(bad, do not use)}
$$

**这个公式不好，以后不要用**

h一般比较小，设置成1e-5差不多了

在实践中，一般使用中心差分g公式( centered difference formula ）

$$
\frac{df(x)}{dx} = \frac{f(x + h) - f(x - h)}{2h} \hspace{0.1in} \text{(use instead)}
$$

这个公式需要对x的每个维度都计算两次损失函数来检查梯度，但是这种方法可以证明会更精确。可以通过$$f(x+h$$和$$f(x-h$$的Talyor 展开式来z证明第一个公式的误差在$$O(h)$$量级，第二个公式的误差在$$O(h^2$$

**Use relative error for the comparison**

怎么才能知道梯度的数值解和解析解比较相近的?我们可能很自然的比较$$\mid f’_a - f’_n \mid$$的值或者对应的平方值，如果大于一定阈值就认为二者不相等。但是这种方法是有问题的。
比如误差是1e-4,如果梯度值在1.0左右时，这个差距看起来比较小，我们认为这两个值是相等的。  但是如果梯度在1e-5或者更低，那么误差为1e-4就是一个非常大的误差，此时我们认为计算是有问题的。所以检查相对误差会更合理:

$$
\frac{\mid f'_a - f'_n \mid}{\max(\mid f'_a \mid, \mid f'_n \mid)}
$$

相对误差考虑了二者之间的差值和梯度的绝对值之间的比例。

相对误差有下面几条指导性的建议

1.相对误差大于1e-2通常意味这计算出错
2.相对误差在(1e-4,1e-2)区间你可能就要怀疑自己的计算是否出错了
3.相对误差小于1e-4对于带有kink的目标函数来说通常还ok,如果没有kinks（使用tanh作为激活函数和softmax)，1e-4可能就太高了
4.1e-7或者更低通常意味着计算是正确的

kinks是指函数中存在不可导的点

记住，网络越深，相对误差会越高。所有如果你对一个10层的网络进行梯度检查，那么相对误差在1e-2可能还ok，因为误差是一路累积的。相反，如果对一个可微函数的梯度相对误差在1e-2就不可接受了。

**Use double precision**

常见的错误是单精度浮点数来进行梯度检查。有时候即使实现正确，单精度浮点数可能也会得到1e-2的相对误差值。


**Stick around active range of floating point**

阅读“What Every Computer Scientist Should Know About Floating-Point Arithmetic”

比如,在一个batch上对损失函数进行归一化，如果每个样本的梯度都很小，那么又除以了样本的个数，那么得到的梯度值就更小了，这样反过来又会导致更多的数值问题。这也是我喜欢打印出原始的数值解和解析解，确定比较的两个值不是非常小的值，通常绝对值在1e-10或者更小你就要注意了。这时你可能需要放大你的损失函数的值到一个更合理的范围。在这个范围里浮点数更加稠密（大概是说0少一些），比较理想的值是量级在1.0上，即浮点数的指数部分为0.

**Kinks in the objective**

目标函数中的不可导点

梯度检查中  不准确的一个来源就是kinks。
kinks是指目标函数中不可导的点。比如ReLU(max(0,x)),或者SVM损失，Maxout 神经元。考虑当x=-1e-6时，对ReLU函数进行梯度检查.既然x<0，那么这个点的梯度解析解就是0.但是计算出来的数值解可能就是一个非零值，因为f(x+h)可能会跨过kinks（h>1e-6),这时候梯度就非0了。你可能会觉得这是一个病态的例子，但是实际上这种例子很常见。

**Use only few datapoints**

解决kink带来的问题的一个方法就是使用更少的样本。因为带有kink的损失函数在样本越少时kinks越少，所以在你进行有限差分近似时遇到kink的可能性就越低。


**Be careful with the step size h**

不一定越少越好，因为h很小时会有数值准确度的问题。

**Gradcheck during a “characteristic” mode of operation**

我们需要认识到梯度检验是在参数空间的一个特定的点上进行的。即使在那个点上检查通过了，也不能立马就能断定梯度实现正确了。另外，一个随机的初始化可能不是参数空间最优代表性的点，这可能导致进入某种病态的情况，即梯度看起来是正确实现了，实际上并没有。比如，如果权重初始值很小,SVM会给所有样本分配一个几乎等于0的值。梯度将会在所有的数据点上展现出某种模式。一个实现错误的梯度可能依然表现出这种模式，而且不能泛化到更具代表性的操作模式，比如在一些得分比另一些得分更大的情况下就不行。所以，安全起见，最好在经过一个预热的过程之后再进行梯度检验。即在预热过程中神经网络开始进行学习，在损失下降后开始进行梯度检验。第一次就进行检验的危险就在于这样可能会引入某些病态的边界情况，掩盖了错误的实现。


**Don’t let the regularization overwhelm the data**

通常损失函数包括数据损失和正则损失，需要注意的是正则损失可能淹没数据损失。此时损失主要来自正则损失（正则损失形式更简单）。这时可能就掩盖了错误的实现。所以一般推荐在梯度检验时关掉正则损失，首先只检查数据损失，然后再单独检查正则损失。单独检查正则损失时可以是修改代码，去掉其中数据损失的部分，也可以提高正则化强度，确认其效果在梯度检查中是无法忽略的，这样不正确的实现就会被观察到了。

**Remember to turn off dropout/augmentations**

梯度检查时去掉任何不确定性的措施，比如dropout，随机数据扩展等。否则在计算数值梯度时他们就会引入巨大的误差。不好的地方在于无法对这些部分进行梯度检验，而他们也有可能实现错误，从而使梯度计算出错。，一个更好的解决方案就是在计算f(x+h)和f(x-h)前强制增加一个特定的随机种子，在计算解析梯度时也同样如此。这样这些包含不确定因素的方法也就变成确定性的了。

**Check only few dimensions**

通常梯度可能有上百万维，此时，只能检查其中一部分纬度，假设其他维度实现是正确的。注意，确保每种不同的参数都被检查了其中几个维度，比如我们为了方便把几种参数合并成了一个向量，比如偏置可能只占向量的很小一部分，此时我们就不能随机选几维，一定要把这种情况考虑到，确保所有参数都收到了正确的梯度。


Before learning: sanity checks Tips/Tricks
====


**Look for correct loss at chance performance**

确保当用小的数值初始化参数时损失值是正确的。最好是先检查数据损失(data loss),比如，对于CIFAR-10数据集，使用softmax分类器时初始的损失函数值应该是2.302， 因为初始化时每个类的概率是0.1,softmax 损失是正确类别的概率的负的对数,即-ln(0.1)=2.302.对于The Weston Watkins SVM，我们期望所有的边界都被越过，因为每个类的分数都基本上为0，所以期望损失为9，因为每个错误类别的边界值是1，如果没看到这些损失值，那么初始化可能就有问题了。

increasing the regularization strength should increase the loss
为啥

Overfit a tiny subset of data.

最重要的一点，在全部训练集上进行训练之前，先在一个很小的数据集（20个样本？）上进行训练，并且确保损失能达到0.在进行实验时，最好把正则化损失设置为0，否则，这个会阻止损失为0，除非你在一个小数据集上通过了sanity check，否则，不值得在全部训练集上进行训练。另外，也需要注意即使你在小数据集上过拟合了，实现有可能还是错误的。比如,因为某些错误，数据点的特征是随机的，这样算法也可能对小数据进行过拟合，但是在整个数据集上跑算法的时候，就没有任何泛化能力。

Babysitting the learning process
====

在训练神经网络时，应该监控多个重要数值.数值输出的图表是观察训练进程的一扇窗口，是直观理解不同的超参数设置效果的工具，

在下面的图表中，x轴通常都是表示周期（epochs）单位，该单位衡量了在训练中每个样本数据都被观察过次数的期望（一个周期意味着每个样本数据都被观察过了一次）。相较于迭代次数（iterations），一般更倾向跟踪周期，这是因为迭代次数与数据的批尺寸（batchsize）有关，而批尺寸的设置又可以是任意的。


Loss function
===

训练过程中首先需要跟踪的就是损失函数，在前向过程中该值是在每个batch上进行计算的。

下图是损失函数随时间的变化,尤其是不同的形状说明了学习率设置的是否合理。

![loss ](http://cs231n.github.io/assets/nn3/learningrates.jpeg)

过低的学习率导致算法的改善是线性的。高一些的学习率会看起来呈几何指数下降，更高的学习率会让损失值很快下降，但是接着就停在一个不好的损失值上（绿线）。这是因为最优化的“能量”太大，参数在混沌中随机震荡，不能最优化到一个很好的点上。

![loss on CIFAR-10 ](http://cs231n.github.io/assets/nn3/loss.jpeg)

显示了一个典型的随时间变化的损失函数值，在CIFAR-10数据集上面训练了一个小的网络，这个损失函数值曲线看起来比较合理（虽然可能学习率有点小，但是很难说），而且指出了批数据的数量可能有点太小（因为损失值的噪音很大）。


损失值的震荡程度(wiggle)和批尺寸（batch size）有关，当批尺寸为1，震荡会相对较大。当批尺寸就是整个数据集时震荡就会最小，因为每个梯度更新都是单调地优化损失函数（除非学习率设置得过高）。


Train/Val accuracy

第二个需要跟踪的数值就是验证集和训练集的准确率，这个图可以帮你判断模型过拟合的程度。

![Train/Val accuracy ](http://cs231n.github.io/assets/nn3/accuracies.jpeg)

在训练集准确率和验证集准确率中间的空隙指明了模型过拟合的程度。在图中，蓝色的验证集曲线显示验证集的准确率比训练集低了很多，这说明模型有很强的过拟合。如果遇到这种情况，就应该增大正则化强度（更强的L2权重惩罚，更多的随机失活(dropout)等）或收集更多的数据。另一种可能就是验证集曲线和训练集曲线十分相近，这种情况说明你的模型容量(capacity)还不够大：应该通过增加参数数量让模型容量更大些。

Ratio of weights:updates
===

最后一个需要跟踪的数值是权重更新值和权重数值本身之间的比例。注意，是更新量，而不是原始梯度（比如，在普通sgd中就是梯度乘以学习率）。
你可能需要对每个参数跟踪和计算这个比例，一个经验性的结论是这个比例应该在1e-3左右。如果更低，说明学习率可能太小，如果更高，说明学习率可能太高。下面是具体例子：

    # 假设参数向量为W，其梯度向量为dW
    param_scale = np.linalg.norm(W.ravel())
    update = -learning_rate*dW # 简单SGD更新
    update_scale = np.linalg.norm(update.ravel())
    W += update # 实际更新
    print update_scale / param_scale # 要得到1e-3左右

Activation / Gradient distributions per layer
===

不正确的初始化可能会减慢甚至使学习过程完全停止，幸运得是这个问题可以比较容易的检测出来，一种方法就是画出神经网络各层的激活函数和梯度的直方图。直观地说，如果看到任何奇怪的分布情况，那都不是好兆头.如果是tanh 神经元，我们期望看到激活函数分布在在(-1,1)之间,而不是全部都输出0，或者全部到饱和到-1或1。

First Layer Visualizations
===

最后，如果你处理的是图像的话，把第一层的特征可视化通常会有帮助。


Parameter updates
====

梯度解析解计算出来后，梯度就可以用来进行参数更新了。下面讨论参数跟新的几种方法。


SGD and bells and whistles
====

**Vanilla update** 最简单的形式就是 沿着负梯度方向更新参数。假设参数向量`x`,梯度向量`dx`,形式如下:

    # Vanilla update
    x += - learning_rate * dx

`learning_rate`是超参数.如果在整个数据集上进行计算，且learning_rate 足够低的话，这种更新可以保证损失函数是不会上升的。

`Momentum update`是另外一种几乎总是收敛得更快的更新方法。该方法可以看成是从物理角度上对于最优化问题得到的启发。损失值可以理解为是山的高度（因此高度势能是U=mgh，所以有U\propto h）。用随机数字初始化参数等同于在某个位置给质点设定初始速度为0。这样最优化过程可以看做是模拟参数向量（即质点）在地形上滚动的过程。


参考：

1.http://cs231n.github.io/neural-networks-3/
2.http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html






