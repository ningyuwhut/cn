---
  layout: post
  title: cs20si 笔记
  categories: MachineLearning
  tags:
---

Lecture 1 Introduction to Tensorflow
====

本节主要介绍了tf的主要概念。

使用tensorflow时有几个地方需要特别注意:

1.不要使用多个Graph

    Multiple graphs require multiple sessions, each will try to use all available resources by default

    Can't pass data between them without passing them through python/numpy, which doesn't work in distributed 

    It’s better to have disconnected subgraphs within one graph


2.不要混用默认的graph和用户自定义的graph,容易出错

下面这段程序是个错误的示范
```   
g = tf.Graph()
# add ops to the default graph
a = tf.constant(3)
# add ops to the user created graph
with g.as_default():
    b = tf.constant(5)
```

下面的程序好一些，但是还不够好，因为使用了多个图

```
g1 = tf.get_default_graph()
g2 = tf.Graph()
# add ops to the default graph
with g1.as_default():
    a = tf.Constant(3)
    # add ops to the user created graph
    with g2.as_default():
	b = tf.Constant(5)
```

关于图的优点


    Save computation. Only run subgraphs that lead to the values you want to fetch.

    Break computation into small, differential pieces to facilitate auto-differentiation

    Facilitate distributed computation, spread the work across multiple CPUs, GPUs, TPUs, or other devices

    Many common machine learning models are taught and visualized as directed graphs


Lecture 2 TensorFlow Ops
====

该节讲解了tf的各种操作、数据类型等方面.

在该练习中遇到了https://stackoverflow.com/questions/34977388/matplotlib-runtimeerror-python-is-not-installed-as-a-framework 中的问题，参考第一个答案即可

在tf中,所有的constants, variables, operators 都是 ops。
tf.constant中的c是小写而tf.Variable的V大写的原因就在于tf.constant是一个op，而tf.Variable是一个包含很多op的类。

比较老的创建Variable的做法是调用"tf.Variable(<initial-value>, name=<optional-name>)"函数。现在不鼓励这样做。tf推荐tf.get_variable，

Variable在使用前必须初始化。否则会遇到"FailedPreconditionError:Attempting to use uninitialized value"。

可以通过如下方法获取没有初始化的变量:

```
print(session.run(tf.report_uninitialized_variables()))
```

```
# V is a 784 x 10 variable of random values
V = tf.get_variable("normal_matrix", shape=(784, 10), 
                     initializer=tf.truncated_normal_initializer())

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(sess.run(V))
    print(V.eval())
#以上两种方法都可以 获取V的值。
```

如何给variables赋值

```

W = tf.Variable(10)
W.assign(100)
with tf.Session() as sess:
	sess.run(W.initializer)
	print(W.eval()) # >> 10
```
上面的程序输出10，原因在于W.assign(100)只是创建了一个assign 运算，并没有真正得执行。如果想要操作生效的话，只需要执行eval操作：

```
W = tf.Variable(10)

assign_op = W.assign(100)
with tf.Session() as sess:
	sess.run(assign_op)
	print(W.eval()) # >> 100
```

这里，我们并没有初始化W，因为assign()已经完成了初始化。实际上，initializer op就是一个把变量初始值赋值给变量的assign op。

Lazy loading

```

x = tf.Variable(10, name='x')
y = tf.Variable(20, name='y')
z = tf.add(x, y)

with tf.Session() as sess:
	sess.run(tf.global_variables_initializer())
	writer = tf.summary.FileWriter('graphs/normal_loading', sess.graph)
	for _ in range(10):
		sess.run(z)
	writer.close()
```

```

x = tf.Variable(10, name='x')
y = tf.Variable(20, name='y')

with tf.Session() as sess:
	sess.run(tf.global_variables_initializer())
	writer = tf.summary.FileWriter('graphs/lazy_loading', sess.graph)
	for _ in range(10):
		sess.run(tf.add(x, y))
	print(tf.get_default_graph().as_graph_def()) 
	writer.close()
```

Lazy loading的含义就是只有当你用到某个op时你才创建它。

上面第一段代码是normal loading，第二段就是lazy loading。区别在于第二段代码在每次迭代中都会创建一个add节点。为了避免这种情况，可以将图的定义和执行分开进行.

Lecture note 3: Linear and Logistic Regression in TensorFlow 
===

